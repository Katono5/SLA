# Source Label Adaptation
The official Pytorch implementation of "Semi-Supervised Domain Adaptation with Source Label Adaptation" accepted by CVPR 2023. Check more details of this work in our paper: [[Arxiv]](https://arxiv.org/abs/2302.02335).

## Python version & Packages

`python==3.8.13`

```
configargparse==1.5.3
torch==1.12.0
torchvision==0.13.0
tensorboard==2.9.0
Pillow==9.0.1
numpy==1.22.3
```

## Data Preparation

### Supported Datasets

Currently, we support the following three datasets:

- [DomainNet](http://ai.bu.edu/M3SDA/)
- [OfficeHome](https://www.hemanthdv.org/officeHomeDataset.html)
- [Office31](https://faculty.cc.gatech.edu/~judy/domainadapt/)

### Dataset Architecture

The dataset is organized into directories, as shown below:

```
- dataset_dir
    - dataset_name
        - domain 1
        - ...
        - domain N
        - text
            - domain 1
                - all.txt
                - train_1.txt
                - train_3.txt
                - test_1.txt
                - test_3.txt
                - val.txt
            - ...
            - domain N
    - ...
```

### Download and Preparation

To download and prepare one of these datasets, run the following command:

```
python data_preparation/data_preparation.py --dataset <DATASET>
```

Replace <DATASET> with the name of the dataset you want to prepare (e.g. DomainNet, OfficeHome, or Office31). This script will download the dataset (if necessary) and extract the text data which specify the way to split training, validation, and test sets. The resulting data will be saved in the format described above.

After running the data preparation script, you should be able to use the resulting data files in this repository.


## Usage

1. Dataset Preparement
    
    Following [MME](https://github.com/VisionLearningGroup/SSDA_MME) to download the dataset and the split files.

    In `config.yaml`, specify the path for the dataset, and the path for the split files.
    - all: the file with all samples.
    - 1shot:
        - train: training split for 1-shot setting.
        - test: test split for 1-shot setting.
    - 3shot:
        - train: training split for 3-shot setting.
        - test: test split for 3-shot setting.
    - val: validation split.

2. Running

Take MME + SLA on 3-shot A -> C Office-Home dataset as example:

```
python --method MME_LC --source 0 --target 1 --seed 1102 --num_iters 10000 --shot 3shot --alpha 0.3 --update_interval 500 --warmup 500 --T 0.6
```

## Acknowledgement

This readme file is partially generated by [ChatGPT](https://chat.openai.com/chat).

This code is partially based on [MME](https://github.com/VisionLearningGroup/SSDA_MME), [CDAC](https://github.com/lijichang/CVPR2021-SSDA) and [DeepDA](https://github.com/jindongwang/transferlearning/tree/master/code/DeepDA).

The backup url for OfficeHome, Office31 is provided by [here](https://github.com/jindongwang/transferlearning/blob/master/data/dataset.md).
